---
title: how to write fast code - Module 1
date: 2017-03-15 20:00:08
categories: STUDY
tags: how to write fast code
---

### M1-2

![mindmap](https://raw.githubusercontent.com/Annashuo/hello-world/master/M1-2.png)

<!--more-->
#### What are the differences between multicore and manycore processors?    

- definition

multicore: each core optimized for executing a single thread.

manycore: cores optimized for aggregate throughput, deemphasizing individual performance.

- similar in scalling trends

	- increasing vector unit width
	- increasing numbers of cores per die
	- increasing bandwidth to off-chip memory

- different in optimization points


#### What is instruction level parallelism? What is SIMD?

1. instruction level parallelism(ILP): instructions in a sequence that can be computed at the same time.

	- multiple valid instruction sequence: compilers may produce valid instruction sequences that have less ILP when executed in order
	- traditional in-order pipeline: an in-order processor pipeline endure ILP and Read/Write operand dependency
	- later out-of-order pipelines: allows instruction re-ordering and uses register-renaming
	- Motivation:Given a single, sequential stream of instructions, how to execute it as fast as possible?
	- Advantages:
		- No changes in sequential software necessary
	- Disadvantages:
		- Significantly more complex processor architecture
		- Longer to design the processor
		- Longer to verify the correctness of the processor design
		- Consumes more energy than simple in-order processor

2. SIMD: single instruction multiple data
	- Motivation: reduce processor complexity by explicitly representing instruction-level parallelism in vector form
	- Advantage: 
		- power-efficient way to improve instruction throughput; 
		- exploitable in many compute-intensive applications
	- Disadvantage: 
		- explicit representation in vector instructions; 
		- software requires re-compilation to take advantage of new SIMD capabilities; 
		- may require hand-tuning to exploit full benefit

#### What is simultaneous multithreading(SMT)?

- Motivation:	- Capturing the opportunity to run faster when more than one thread of instructions are available- Advantage:
	- Gain power-efficiency by increasing processor pipeline utilization
- Disadvantage:
	- Requires multiple threads available
	- May trigger conflicts in shared cache execution
	- Does not improve latency of each thread

#### What are the three metrics for a memory hierarchy?

- Capacity: size
- Latency: from start to finish, in units of time
- Throughput: tasks accomplished per unit time

#### What are the different system granularities?

- Multicore: SIMD level parallelism, core level parallelism, memory hierarchy
- Manycore: GPU System Architecture
- The Cloud

#### How is this relevant to writing fast code?

1. Fast Platforms
	- Multicore platforms
	- Manycore platforms
	- Cloud platforms
2. Good Texhniques
	- Data structures
	- Algorithms
	- Software Architecture

### M1-3

#### What is the difference between concurrency and parallelism?

We expose concurrency in our applications.

We exploit parallelism in our platforms
#### What are the four key elements of the human problem solving process? 

1. Understand the current state
2. Observe the internal representation
3. Search among altenatives
4. Select from a set of choices

#### What are the characteristics of a current algorithm implementation?

- Initialization
- Expectation
- Maximization
- Evaluate
#### What levels of concurrency can be exposed in the k-mean algorithm?

- Initialization: when define distance metric(Euclidian), D(sum reduction) <- euclid_dist_2()
- Expectation: when evaluate distance to each cluster centroid and select closest, N(independent); D(sum reduction) <- euclid_dist_2(); k(min reduction)
- Maximization: when calculate new cluster centroid, D(independent); N(Histogram computation into k bins)
#### What levels of parallelism are available to be exploited?

- Multicore and manycore parallelism
- Memory Hierarchy
#### What mapping between concurrency and parallelism can be explored?

- SIMD & core-level parallelism across data-points(N)
	- Update menbership for each data point sequentially
	- Histogram computation(summation/assignment count for new clusters)
- OpenMP
#### How is this relevant to writing fast code?
- Expose concurrencies in allications and algorithms
- Exploit parallelisms on application platform
- Explore mapping between concurrency and parallelism

